{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iwiWSBX-gz9w",
    "outputId": "06812c38-08e3-4df2-8cbb-637af993cdb5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_1412\\3600170309.py:41: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  corr_matrix = data.corr()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Columns:\n",
      "['Status', 'Soort bouw', 'Energielabel', 'Aantal dagen tot verkoop', 'Soort dak', 'Soort woonhuis']\n",
      "Numerical Columns:\n",
      "['Laatste vraagprijs', 'Aantal kamers', 'Overige inpandige ruimte m2', 'Perceel m2', 'Achtertuin m2', 'Vraagprijs per m2', 'Woonruimte in m2', 'Gebouwgebonden buitenruimte in m2', 'Externe bergruimte in m2', 'Inhoud in m3', 'Aantal slaapkamers', 'Bathrooms', 'Toilets', 'Kelder', 'Voorzieningen_Domotica', 'Voorzieningen_Zwembad', 'Voorzieningen_Verwarming', 'Voorzieningen_Stromendwater', 'Voorzieningen_Elektrischedeur', 'Voorzieningen_Alarminstallatie', 'Isolatie_Vollediggeïsoleerd', 'Verwarming_Gedeeltelijkevloerverwarming', 'Verwarming_Warmtepomp', 'Verwarming_Gehelevloerverwarming', 'Verwarming_Blokverwarming', 'Verwarming_Gashaard', 'Verwarming_Openhaard', 'Verwarming_Houtkachel', 'Balkon/dakterras_Dakterrasaanwezig', 'Tuin_Zijtuin', 'Tuin_Tuinrondom', 'Soort garage_Parkeerplaats', 'Soort garage_Inpandig', 'Soort garage_Parkeerkelder']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 132.60093| val_0_mae: 11.03966| val_0_mse: 122.05075| val_0_rmse: 11.04766|  0:00:02s\n",
      "epoch 1  | loss: 58.7985 | val_0_mae: 7.37748 | val_0_mse: 54.74439| val_0_rmse: 7.39894 |  0:00:05s\n",
      "epoch 2  | loss: 20.18549| val_0_mae: 2.72553 | val_0_mse: 7.92119 | val_0_rmse: 2.81446 |  0:00:08s\n",
      "epoch 3  | loss: 13.48406| val_0_mae: 3.26612 | val_0_mse: 11.49678| val_0_rmse: 3.39069 |  0:00:11s\n",
      "epoch 4  | loss: 5.79684 | val_0_mae: 1.78896 | val_0_mse: 3.67781 | val_0_rmse: 1.91776 |  0:00:13s\n",
      "epoch 5  | loss: 2.34952 | val_0_mae: 1.76231 | val_0_mse: 3.37132 | val_0_rmse: 1.83612 |  0:00:16s\n",
      "epoch 6  | loss: 1.4596  | val_0_mae: 0.90305 | val_0_mse: 1.03117 | val_0_rmse: 1.01547 |  0:00:19s\n",
      "epoch 7  | loss: 0.81547 | val_0_mae: 0.652   | val_0_mse: 0.63041 | val_0_rmse: 0.79398 |  0:00:21s\n",
      "epoch 8  | loss: 0.5516  | val_0_mae: 0.54296 | val_0_mse: 0.43347 | val_0_rmse: 0.65839 |  0:00:24s\n",
      "epoch 9  | loss: 0.446   | val_0_mae: 0.55376 | val_0_mse: 0.44358 | val_0_rmse: 0.66602 |  0:00:27s\n",
      "epoch 10 | loss: 0.38286 | val_0_mae: 0.3286  | val_0_mse: 0.18034 | val_0_rmse: 0.42467 |  0:00:30s\n",
      "epoch 11 | loss: 0.45497 | val_0_mae: 0.4506  | val_0_mse: 0.31559 | val_0_rmse: 0.56177 |  0:00:32s\n",
      "epoch 12 | loss: 0.41199 | val_0_mae: 0.42474 | val_0_mse: 0.29077 | val_0_rmse: 0.53923 |  0:00:35s\n",
      "epoch 13 | loss: 0.39092 | val_0_mae: 0.48766 | val_0_mse: 0.36845 | val_0_rmse: 0.607   |  0:00:38s\n",
      "epoch 14 | loss: 0.29836 | val_0_mae: 0.36643 | val_0_mse: 0.22385 | val_0_rmse: 0.47313 |  0:00:41s\n",
      "epoch 15 | loss: 0.26855 | val_0_mae: 0.33254 | val_0_mse: 0.18966 | val_0_rmse: 0.4355  |  0:00:43s\n",
      "epoch 16 | loss: 0.27025 | val_0_mae: 0.31951 | val_0_mse: 0.17585 | val_0_rmse: 0.41934 |  0:00:46s\n",
      "epoch 17 | loss: 0.28354 | val_0_mae: 0.50581 | val_0_mse: 0.37732 | val_0_rmse: 0.61427 |  0:00:49s\n",
      "epoch 18 | loss: 0.27786 | val_0_mae: 0.3992  | val_0_mse: 0.25393 | val_0_rmse: 0.50391 |  0:00:52s\n",
      "epoch 19 | loss: 0.19192 | val_0_mae: 0.3186  | val_0_mse: 0.16859 | val_0_rmse: 0.41059 |  0:00:54s\n",
      "epoch 20 | loss: 0.20802 | val_0_mae: 0.36104 | val_0_mse: 0.20215 | val_0_rmse: 0.44961 |  0:00:57s\n",
      "epoch 21 | loss: 0.17591 | val_0_mae: 0.27618 | val_0_mse: 0.1286  | val_0_rmse: 0.35861 |  0:01:00s\n",
      "epoch 22 | loss: 0.18053 | val_0_mae: 0.53534 | val_0_mse: 0.3759  | val_0_rmse: 0.61311 |  0:01:03s\n",
      "epoch 23 | loss: 0.32663 | val_0_mae: 0.2767  | val_0_mse: 0.12675 | val_0_rmse: 0.35601 |  0:01:06s\n",
      "epoch 24 | loss: 0.27994 | val_0_mae: 0.26827 | val_0_mse: 0.11442 | val_0_rmse: 0.33826 |  0:01:08s\n",
      "epoch 25 | loss: 0.23407 | val_0_mae: 0.38378 | val_0_mse: 0.20475 | val_0_rmse: 0.4525  |  0:01:11s\n",
      "epoch 26 | loss: 0.17723 | val_0_mae: 0.24541 | val_0_mse: 0.09848 | val_0_rmse: 0.31381 |  0:01:14s\n",
      "epoch 27 | loss: 0.15767 | val_0_mae: 0.26766 | val_0_mse: 0.11904 | val_0_rmse: 0.34502 |  0:01:17s\n",
      "epoch 28 | loss: 0.14956 | val_0_mae: 0.28994 | val_0_mse: 0.13421 | val_0_rmse: 0.36635 |  0:01:20s\n",
      "epoch 29 | loss: 0.14475 | val_0_mae: 0.2545  | val_0_mse: 0.10729 | val_0_rmse: 0.32756 |  0:01:22s\n",
      "epoch 30 | loss: 0.13678 | val_0_mae: 0.24952 | val_0_mse: 0.10604 | val_0_rmse: 0.32564 |  0:01:25s\n",
      "epoch 31 | loss: 0.12776 | val_0_mae: 0.29319 | val_0_mse: 0.13304 | val_0_rmse: 0.36474 |  0:01:28s\n",
      "epoch 32 | loss: 0.13084 | val_0_mae: 0.24579 | val_0_mse: 0.10061 | val_0_rmse: 0.31719 |  0:01:31s\n",
      "epoch 33 | loss: 0.12629 | val_0_mae: 0.24166 | val_0_mse: 0.09817 | val_0_rmse: 0.31333 |  0:01:33s\n",
      "epoch 34 | loss: 0.12127 | val_0_mae: 0.26937 | val_0_mse: 0.11879 | val_0_rmse: 0.34466 |  0:01:36s\n",
      "epoch 35 | loss: 0.12224 | val_0_mae: 0.23098 | val_0_mse: 0.08992 | val_0_rmse: 0.29987 |  0:01:39s\n",
      "epoch 36 | loss: 0.11416 | val_0_mae: 0.2554  | val_0_mse: 0.10377 | val_0_rmse: 0.32213 |  0:01:42s\n",
      "epoch 37 | loss: 0.11773 | val_0_mae: 0.28332 | val_0_mse: 0.12305 | val_0_rmse: 0.35078 |  0:01:45s\n",
      "epoch 38 | loss: 0.11532 | val_0_mae: 0.23364 | val_0_mse: 0.08882 | val_0_rmse: 0.29803 |  0:01:47s\n",
      "epoch 39 | loss: 0.11058 | val_0_mae: 0.22109 | val_0_mse: 0.08409 | val_0_rmse: 0.28999 |  0:01:50s\n",
      "epoch 40 | loss: 0.10985 | val_0_mae: 0.24167 | val_0_mse: 0.09695 | val_0_rmse: 0.31137 |  0:01:53s\n",
      "epoch 41 | loss: 0.10545 | val_0_mae: 0.20676 | val_0_mse: 0.07561 | val_0_rmse: 0.27496 |  0:01:56s\n",
      "epoch 42 | loss: 0.10221 | val_0_mae: 0.19647 | val_0_mse: 0.06885 | val_0_rmse: 0.26239 |  0:01:59s\n",
      "epoch 43 | loss: 0.08783 | val_0_mae: 0.17012 | val_0_mse: 0.05432 | val_0_rmse: 0.23307 |  0:02:02s\n",
      "epoch 44 | loss: 0.08172 | val_0_mae: 0.16063 | val_0_mse: 0.05205 | val_0_rmse: 0.22814 |  0:02:04s\n",
      "epoch 45 | loss: 0.06712 | val_0_mae: 0.1565  | val_0_mse: 0.04871 | val_0_rmse: 0.2207  |  0:02:07s\n",
      "epoch 46 | loss: 0.06324 | val_0_mae: 0.17246 | val_0_mse: 0.05575 | val_0_rmse: 0.23611 |  0:02:10s\n",
      "epoch 47 | loss: 0.06475 | val_0_mae: 0.13617 | val_0_mse: 0.04202 | val_0_rmse: 0.205   |  0:02:12s\n",
      "epoch 48 | loss: 0.05819 | val_0_mae: 0.15446 | val_0_mse: 0.04763 | val_0_rmse: 0.21824 |  0:02:15s\n",
      "epoch 49 | loss: 0.05611 | val_0_mae: 0.12014 | val_0_mse: 0.03634 | val_0_rmse: 0.19062 |  0:02:18s\n",
      "epoch 50 | loss: 0.05195 | val_0_mae: 0.11376 | val_0_mse: 0.0336  | val_0_rmse: 0.1833  |  0:02:21s\n",
      "epoch 51 | loss: 0.05392 | val_0_mae: 0.14152 | val_0_mse: 0.04784 | val_0_rmse: 0.21872 |  0:02:23s\n",
      "epoch 52 | loss: 0.05046 | val_0_mae: 0.11813 | val_0_mse: 0.04651 | val_0_rmse: 0.21565 |  0:02:26s\n",
      "epoch 53 | loss: 0.04683 | val_0_mae: 0.11905 | val_0_mse: 0.0381  | val_0_rmse: 0.19519 |  0:02:29s\n",
      "epoch 54 | loss: 0.04648 | val_0_mae: 0.10851 | val_0_mse: 0.0337  | val_0_rmse: 0.18357 |  0:02:32s\n",
      "epoch 55 | loss: 0.04856 | val_0_mae: 0.18179 | val_0_mse: 0.04956 | val_0_rmse: 0.22262 |  0:02:34s\n",
      "epoch 56 | loss: 0.0765  | val_0_mae: 0.18568 | val_0_mse: 0.05004 | val_0_rmse: 0.22369 |  0:02:37s\n",
      "epoch 57 | loss: 0.09365 | val_0_mae: 0.3342  | val_0_mse: 0.12976 | val_0_rmse: 0.36022 |  0:02:40s\n",
      "epoch 58 | loss: 0.1259  | val_0_mae: 0.14608 | val_0_mse: 0.03872 | val_0_rmse: 0.19678 |  0:02:42s\n",
      "epoch 59 | loss: 0.07904 | val_0_mae: 0.13403 | val_0_mse: 0.0322  | val_0_rmse: 0.17943 |  0:02:45s\n",
      "epoch 60 | loss: 0.06622 | val_0_mae: 0.12931 | val_0_mse: 0.02831 | val_0_rmse: 0.16825 |  0:02:47s\n",
      "epoch 61 | loss: 0.0445  | val_0_mae: 0.13181 | val_0_mse: 0.03309 | val_0_rmse: 0.1819  |  0:02:50s\n",
      "epoch 62 | loss: 0.04143 | val_0_mae: 0.14707 | val_0_mse: 0.03602 | val_0_rmse: 0.18979 |  0:02:52s\n",
      "epoch 63 | loss: 0.06716 | val_0_mae: 0.26159 | val_0_mse: 0.08063 | val_0_rmse: 0.28395 |  0:02:55s\n",
      "epoch 64 | loss: 0.12407 | val_0_mae: 0.21469 | val_0_mse: 0.05695 | val_0_rmse: 0.23863 |  0:02:57s\n",
      "epoch 65 | loss: 0.06086 | val_0_mae: 0.14144 | val_0_mse: 0.03168 | val_0_rmse: 0.178   |  0:03:00s\n",
      "epoch 66 | loss: 0.05639 | val_0_mae: 0.15436 | val_0_mse: 0.03605 | val_0_rmse: 0.18987 |  0:03:03s\n",
      "epoch 67 | loss: 0.04169 | val_0_mae: 0.08576 | val_0_mse: 0.01985 | val_0_rmse: 0.1409  |  0:03:05s\n",
      "epoch 68 | loss: 0.03681 | val_0_mae: 0.20201 | val_0_mse: 0.05098 | val_0_rmse: 0.22578 |  0:03:08s\n",
      "epoch 69 | loss: 0.06012 | val_0_mae: 0.156   | val_0_mse: 0.03601 | val_0_rmse: 0.18976 |  0:03:10s\n",
      "epoch 70 | loss: 0.06072 | val_0_mae: 0.22004 | val_0_mse: 0.06198 | val_0_rmse: 0.24896 |  0:03:13s\n",
      "epoch 71 | loss: 0.05374 | val_0_mae: 0.14659 | val_0_mse: 0.03579 | val_0_rmse: 0.18919 |  0:03:15s\n",
      "epoch 72 | loss: 0.04122 | val_0_mae: 0.13039 | val_0_mse: 0.03076 | val_0_rmse: 0.17537 |  0:03:17s\n",
      "epoch 73 | loss: 0.0459  | val_0_mae: 0.19953 | val_0_mse: 0.0534  | val_0_rmse: 0.23108 |  0:03:20s\n",
      "epoch 74 | loss: 0.04895 | val_0_mae: 0.1372  | val_0_mse: 0.03278 | val_0_rmse: 0.18104 |  0:03:22s\n",
      "epoch 75 | loss: 0.04462 | val_0_mae: 0.10243 | val_0_mse: 0.02445 | val_0_rmse: 0.15636 |  0:03:25s\n",
      "epoch 76 | loss: 0.04557 | val_0_mae: 0.16625 | val_0_mse: 0.03935 | val_0_rmse: 0.19838 |  0:03:27s\n",
      "epoch 77 | loss: 0.04657 | val_0_mae: 0.09488 | val_0_mse: 0.02436 | val_0_rmse: 0.15609 |  0:03:30s\n",
      "\n",
      "Early stopping occurred at epoch 77 with best_epoch = 67 and best_val_0_rmse = 0.1409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabNet - MAE: 43565.38967563293 MSE: 10849646437.527084 R2 Score: 0.78640797904675\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_tabnet scikit-learn pandas\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Funda_dataset_cleaned.csv')\n",
    "data.drop(['Aangeboden sinds', 'Verkoopdatum'], axis=1, inplace=True)\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = data.corr()\n",
    "\n",
    "# Select the variables that have a correlation less than 0.1 with the target variable\n",
    "drop_list = corr_matrix[corr_matrix['Laatste vraagprijs'].abs() < 0.1].index.to_list()\n",
    "\n",
    "# Drop the variables from the data\n",
    "data = data.drop(drop_list, axis=1)\n",
    "\n",
    "\n",
    "numerical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Select categorical columns with fewer than 1000 unique values\n",
    "categorical_col = [col for col in data.columns if data[col].dtype == 'O' and data[col].nunique() < 1000]\n",
    "\n",
    "\n",
    "numerical_col = [col for col in data.columns if data[col].dtype in ['float64', 'int64']]\n",
    "\n",
    "\n",
    "my_cols = categorical_col + numerical_col\n",
    "\n",
    "#  ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_transformer, numerical_col),\n",
    "    ('cat', categorical_transformer, categorical_col)])\n",
    "\n",
    "\n",
    "eval_set_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "# Selected columns for training\n",
    "selected_columns = ['Status', 'Soort bouw', 'Energielabel', 'Aantal dagen tot verkoop', 'Soort dak', 'Soort woonhuis',\n",
    "                     'Laatste vraagprijs', 'Aantal kamers', 'Overige inpandige ruimte m2', 'Perceel m2', 'Achtertuin m2',\n",
    "                     'Vraagprijs per m2', 'Woonruimte in m2', 'Gebouwgebonden buitenruimte in m2', 'Externe bergruimte in m2',\n",
    "                     'Inhoud in m3', 'Aantal slaapkamers', 'Bathrooms', 'Toilets', 'Kelder', 'Voorzieningen_Domotica',\n",
    "                     'Voorzieningen_Zwembad', 'Voorzieningen_Verwarming', 'Voorzieningen_Stromendwater', 'Voorzieningen_Elektrischedeur',\n",
    "                     'Voorzieningen_Alarminstallatie', 'Isolatie_Vollediggeïsoleerd', 'Verwarming_Gedeeltelijkevloerverwarming',\n",
    "                     'Verwarming_Warmtepomp', 'Verwarming_Gehelevloerverwarming', 'Verwarming_Blokverwarming', 'Verwarming_Gashaard',\n",
    "                     'Verwarming_Openhaard', 'Verwarming_Houtkachel', 'Balkon/dakterras_Dakterrasaanwezig', 'Tuin_Zijtuin',\n",
    "                     'Tuin_Tuinrondom', 'Soort garage_Parkeerplaats', 'Soort garage_Inpandig', 'Soort garage_Parkeerkelder']\n",
    "\n",
    "selected_data = data[selected_columns]\n",
    "\n",
    "X = data.drop('Laatste vraagprijs', axis=1)\n",
    "y = data['Laatste vraagprijs']\n",
    "#y_log = np.log1p(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Create the preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Applying the transformations\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# Initialize TabNetRegressor with adjusted hyperparameters\n",
    "regressor = TabNetRegressor(\n",
    "    n_d=16,\n",
    "    n_a=16,\n",
    "    n_steps=5,\n",
    "    gamma=1.3,\n",
    "    lambda_sparse=0.001,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    mask_type='entmax',\n",
    "    scheduler_params=dict(max_lr=0.05, steps_per_epoch=100, epochs=20),\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "regressor.fit(\n",
    "    X_train_preprocessed, y_train.values.reshape(-1, 1),\n",
    "    eval_set=[(X_test_preprocessed, y_test.values.reshape(-1, 1))],\n",
    "    max_epochs=100,\n",
    "    eval_metric=['mae', 'mse', 'rmse']\n",
    ")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred_tabnet = regressor.predict(X_test_preprocessed)\n",
    "\n",
    "# Calculate metrics on the original scale\n",
    "y_test_pred_original_scale = np.expm1(y_test_pred_tabnet)\n",
    "y_test_original_scale = np.expm1(y_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test_original_scale, y_test_pred_original_scale)\n",
    "mse = mean_squared_error(y_test_original_scale, y_test_pred_original_scale)\n",
    "r2 = r2_score(y_test_original_scale, y_test_pred_original_scale)\n",
    "\n",
    "print(\"TabNet - MAE:\", mae, \"MSE:\", mse, \"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oS1qZJ06xQjK",
    "outputId": "31bf2a2e-0342-42ab-d30c-83e9c2f4480b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104161.63611199224\n"
     ]
    }
   ],
   "source": [
    "#RMSE\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
